{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH04_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTLI8k8TjKK04Gwyi94yRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GyeeunJeong/nlp_with_pytorch_examples/blob/master/CH04_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJq76fUfaS7r",
        "colab_type": "text"
      },
      "source": [
        "# 4. 전처리\n",
        "\n",
        "## 4.1.1 코퍼스(corpus)\n",
        "* 단일언어 코퍼스(monolingual) : 한 가지 언어로 구성\n",
        "* 이중언어 코퍼스(bilingual) : 두 개의 언어로 구성\n",
        "* 다중언어 코퍼스 (multilingual)\n",
        "* 병렬 코퍼스 (parallel) : 언어 간에 쌍으로 구성\n",
        "\n",
        "## 4.1.2 전처리 과정 개요\n",
        "1. 코퍼스 수집\n",
        "    - robots.txt로 크롤링 허용 여부 확인\n",
        "2. 정제(normalization)\n",
        "    - 전각문자제거, 대소문자제거 등. 정규표현식 사용.\n",
        "3. 문장 단위 분절\n",
        "4. 분절\n",
        "5. 병렬 코퍼스 정렬(생략가능)\n",
        "6. 서브워드 분절"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZnnMJuT00un",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 문장 단위 분절"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlvGHe5dzIX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, fileinput, re\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnXzycPi5Nrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "29181786-25b5-4ae0-acf7-7732aa661f0a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCWTgsMHy_ru",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.1 문장 단위 분절 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyyH-_QnzZdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c5788006-9d00-42d1-ea2d-549394bde15f"
      },
      "source": [
        "ex_sen = '자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을 받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 있게 된 것입니다.'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #for line in fileinput.input():\n",
        "  line = ex_sen\n",
        "  if line.strip() != \"\":\n",
        "    line = re.sub(r'([a-z])\\.([A-Z])', r'\\1. \\2', line.strip())\n",
        "    sentences = sent_tokenize(line.strip())\n",
        "\n",
        "    for s in sentences:\n",
        "      if s!= \"\":\n",
        "        sys.stdout.write(s+\"\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "자연어처리는 인공지능의 한 줄기 입니다.\n",
            "시퀀스 투 시퀀스의 등장 이후로 딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다.\n",
            "문장을 받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 있게 된 것입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pNkohLGL05si"
      },
      "source": [
        "### 4.4.2 문장 합치기 및 분절 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lteBM-tZ05sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6a4abd5f-4e54-4737-f607-ddc7c2cec9b9"
      },
      "source": [
        "ex_sen2 = \"\"\"자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 \\n\n",
        "딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을 \\n\n",
        "받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 \\n\n",
        "있게 된 것입니다.\"\"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  buf = []\n",
        "  #for line in fileinput.input():\n",
        "  for line in ex_sen2.splitlines():\n",
        "    if line.strip() != \"\":\n",
        "      buf += [line.strip()]\n",
        "      sentences = sent_tokenize(\" \".join(buf))\n",
        "\n",
        "      if len(sentences)>1:\n",
        "        buf = sentences[-1:]\n",
        "        sys.stdout.write('\\n'.join(sentences[:-1])+'\\n')\n",
        "\n",
        "  sys.stdout.write(' '.join(buf) + '\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "자연어처리는 인공지능의 한 줄기 입니다.\n",
            "시퀀스 투 시퀀스의 등장 이후로 딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다.\n",
            "문장을 받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 있게 된 것입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9ye1za042t",
        "colab_type": "text"
      },
      "source": [
        "## 4.5.2 영어 분절\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiIf-jeD7yd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "948c5ac4-2655-4bb2-95e5-02475e123af9"
      },
      "source": [
        "nltk.download('perluniprops')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwXeq-E7tXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.moses import MosesTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GxTni8T8wwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "9f4b3630-1814-4fad-a0f0-f8a09e903e33"
      },
      "source": [
        "nltk.download('nonbreaking_prefixes')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0pIde-Z701f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c5404a71-648a-4d86-ddec-598c2cab2536"
      },
      "source": [
        "ex_sen3 = \"\"\"Natural language processing is one of biggest streams in artificial intelligence, and it becomes very popular after seq2seq's invention\"\"\"\n",
        "\n",
        "t = MosesTokenizer()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #for line in fileinput.input():\n",
        "  for line in ex_sen3.splitlines():\n",
        "    if line.strip() != '':\n",
        "      tokens = t.tokenize(line.strip(), escape=False)\n",
        "\n",
        "      sys.stdout.write(' '.join(tokens)+'\\n')\n",
        "\n",
        "    else:\n",
        "      sys.stdout.write('\\n')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Natural language processing is one of biggest streams in artificial intelligence , and it becomes very popular after seq2seq 's invention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3HZafn79OSg",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 병렬 코퍼스 정렬\n",
        "1. 소스언어, 타깃언어 사이의 단어사전 준비\n",
        "  - 단어 사전  \n",
        "    1) 각 언어에 대해 코퍼스 수집 및 정제  \n",
        "    2) 각 언어에 대해 단어 임베딩 벡터 구함  \n",
        "    3) MUSE로 단어 레벨 번역기 훈련 -> 단어 사전 생성\n",
        "2. 단어사전, Champollion을 통해 기존 수집된 다중 언어 코퍼스 정렬\n",
        "3. 각 언어 정제(Tokenization, Detokenization)\n",
        "4. Champollion으로 병렬 코퍼스 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achVWh7e-BN1",
        "colab_type": "text"
      },
      "source": [
        "# 4.9 토치텍스트\n",
        "* 전처리 라이브러리 실습\n",
        "* x      -  y    -  활용분야\n",
        "1. 코퍼스  클래스   텍스트 분류, 감성 분석\n",
        "2. 코퍼스  -        언어모델\n",
        "3. 코퍼스  코퍼스   기계번역, 요약, 질의응답"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw3LZtRG_4d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
